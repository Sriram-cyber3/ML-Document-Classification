#-------------------------------------------------------------------------------

import os
import PyPDF2
from collections import Counter
import pandas as pd
import win32com.client
import tkinter as tk
from tkinter import filedialog
import matplotlib.pyplot as plt
import nltk
import re
from collections import Counter, defaultdict
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import fitz  # PyMuPDF - for handling PDFs

def preprocess(text):
    # Lowercase the text
    text = text.lower()
    
    # Remove special characters and numbers
    text = re.sub(r'[^a-z\s]', '', text)
    
    # Tokenize the text
    words = word_tokenize(text)
    
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    words = [word for word in words if word not in stop_words]
    
    # Lemmatize words
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]
    return words

def mow(words):
    # Count word frequencies
    word_counts = Counter(words)
    
    # Get the top 5 most common words
    top_words = word_counts.most_common(5)
    return top_words

def data_vis(top_words):
    words, frequencies = zip(*top_words)  # Unzip the data into two lists
    # Create a bar chart
    plt.bar(words, frequencies, color='skyblue')
    plt.title('Word Frequencies')
    plt.xlabel('Words')
    plt.ylabel('Frequency')
    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
    plt.show(block=False)
    plt.pause(3)
    plt.close()

def convert_doc_to_pdf(doc_path, pdf_path):
    word = win32com.client.Dispatch("Word.Application")
    word.Visible = False  # Optionally, hide the Word window
    doc = word.Documents.Open(doc_path)  # Open the document (Important! Without this, we can't interact with the document)
    doc.SaveAs(pdf_path, FileFormat=17)  # 17 is the PDF format # Save as PDF (this will work only after opening the document)
    doc.Close()  # Close the document and quit Word
    word.Quit()

def get_directory():
    root = tk.Tk()
    root.withdraw()  # Hide the main tkinter window
    folder_path = filedialog.askdirectory(title="Select a Folder")
    folder_path = os.path.normpath(folder_path)
    if folder_path:
        print(f"Selected folder: {folder_path}")
    else:
        print("No folder selected.")
    return folder_path

def summary_visualization(folder_stats, total_files, total_words):
    # Visualize folder-wise file count
    labels = list(folder_stats.keys())
    file_counts = [folder_stats[label]['file_count'] for label in labels]
    word_counts = [folder_stats[label]['word_count'] for label in labels]
    page_counts = [folder_stats[label]['page_count'] for label in labels]

    # Bar chart for files per folder
    plt.bar(labels, file_counts, color='green')
    plt.title('Number of Files Processed Per Folder')
    plt.xlabel('Folder Name')
    plt.ylabel('File Count')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # Bar chart for total words per folder
    plt.bar(labels, word_counts, color='orange')
    plt.title('Total Words Extracted Per Folder')
    plt.xlabel('Folder Name')
    plt.ylabel('Word Count')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Bar chart for total pages per folder
    plt.bar(labels, page_counts, color='red')
    plt.title('Total Pages Per Folder')
    plt.xlabel('Folder Name')
    plt.ylabel('Page Count')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # Display summary statistics
    print("\n=== Summary ===")
    print(f"Total Files Processed: {total_files}")
    print(f"Total Words Extracted: {total_words}")
    #print(f"Total Pages Extracted: {total_pages}")



folder_path = get_directory()

if os.path.exists(folder_path) and os.path.isdir(folder_path): #checks if the folder path is valid
    print("Your data has been recieved, we will shortly provide you the output. Thank you.")
    et_data=[]

    total_files = 0
    total_words = 0
    folder_stats = defaultdict(lambda: {'file_count': 0, 'word_count': 0, 'page_count': 0})

    for root, dir, files in os.walk(folder_path):
        for file in files:
            file_path = os.path.join(root, file)
            print(f"Processing file: {file_path}")
            folder_name = os.path.basename(os.path.dirname(file_path))
            if file_path.endswith((".doc",".docx")):
                output_path = os.path.splitext(file_path)[0] + '.pdf'
                convert_doc_to_pdf(file_path, output_path)
                file_path = output_path          
            if file_path.endswith(".pdf"):
                
                reader = PyPDF2.PdfReader(file_path) 
                text = ""
                contains_images=False
                for page_num, page in enumerate(reader.pages):
                    # Attempt to extract text from the page
                    page_text = page.extract_text()
                    if page_text and page_text.strip():
                        text += page_text
                    else:     
                        # Check if the page contains images
                        pdf_page = fitz.open(file_path)[page_num]
                        if pdf_page.get_images(full=True):
                            contains_images = True
                            break
                    
                if text.strip():  # If there's any text content and no images/ not contains_images and
                    preprocessed_text = preprocess(text)
                    top_words=mow(preprocessed_text)
                    # Extract the first five words
                    first_five_words = [word for word, _ in top_words[:5]]  
                    result = ' '.join(preprocessed_text)
                    w5 = ', '.join(first_five_words)
                    et_data.append({'Extracted content': result, 'Label':folder_name, 'Most Occuring word': w5})
                    # Update stats
                    num_words = len(preprocessed_text)
                    total_files += 1
                    total_words += num_words
                    pages = len(reader.pages)
                    folder_stats[folder_name]['file_count'] += 1
                    folder_stats[folder_name]['word_count'] += num_words
                    folder_stats[folder_name]['page_count'] += pages
                    data_vis(top_words)
    df=pd.DataFrame(et_data)
    df.to_excel("example_pandas.xlsx", index=False)

    # Visualize summary
    summary_visualization(folder_stats, total_files, total_words)
    
else:
    print("Invalid folder path. Please try again.")
